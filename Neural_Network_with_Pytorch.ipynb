{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_with_Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSQd9rAqxVwvkujuFs74GU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyGiusepe/Neural_Network_from_scratch_only_with_Python/blob/main/Neural_Network_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align=\"center\">Rede Neural usando PyTorch</h2>\n",
        "\n",
        "\n",
        "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
      ],
      "metadata": {
        "id": "ZC3G5WjPd_0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este script foi baseado no tutorial de [Pepe Cantoral, PhD](https://www.youtube.com/watch?v=qQELiV1_GHA&list=PLWzLQn_hxe6ZlC9-YMt3nN0Eo-ZpOJuXd&index=21).\n",
        "\n",
        "\n",
        "Neste estudo usaremos `PyTorch` com a ideia de aproveitar o este Framework de Deep Learning. Para começar utilizaremos apenas o `Modulo Sequential`."
      ],
      "metadata": {
        "id": "fBT-Fk2JeLBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "6OvvE5qIfeZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Lu25eWgDXq",
        "outputId": "3c197af5-0e4d-4cb0-84ca-79178f6e8c9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importamos as nossas bibliotecas"
      ],
      "metadata": {
        "id": "Wn3H071Gfu8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6RQwkGfudoPp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos as nossas Imagens"
      ],
      "metadata": {
        "id": "wwg2npmuf005"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar MNIST\n",
        "# Ver vídeo para aprender a importar estes Dados: https://www.youtube.com/watch?v=7cMKAlnSmpM\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "def list_files(mnist_path):\n",
        "    return [join(mnist_path,f) for f in os.listdir(mnist_path) if isfile(join(mnist_path, f))]\n",
        "\n",
        "def get_images(mnist_path):\n",
        "    for f in list_files(mnist_path):\n",
        "        if 'train-images' in f:\n",
        "            with gzip.open(f, 'rb') as data:\n",
        "                _ = int.from_bytes(data.read(4), 'big')\n",
        "                num_images = int.from_bytes(data.read(4), 'big')\n",
        "                rows = int.from_bytes(data.read(4), 'big')\n",
        "                cols = int.from_bytes(data.read(4), 'big')\n",
        "                train_images = data.read()\n",
        "                x_train = np.frombuffer(train_images, dtype=np.uint8)\n",
        "                x_train = x_train.reshape((num_images, rows, cols))\n",
        "        elif 'train-labels' in f:\n",
        "            with gzip.open(f, 'rb') as data:\n",
        "                train_labels = data.read()[8:]\n",
        "                y_train = np.frombuffer(train_labels, dtype=np.uint8)\n",
        "        if 't10k-images' in f:\n",
        "            with gzip.open(f, 'rb') as data:\n",
        "                _ = int.from_bytes(data.read(4), 'big')\n",
        "                num_images = int.from_bytes(data.read(4), 'big')\n",
        "                rows = int.from_bytes(data.read(4), 'big')\n",
        "                cols = int.from_bytes(data.read(4), 'big')\n",
        "                test_images = data.read()\n",
        "                x_test = np.frombuffer(test_images, dtype=np.uint8)\n",
        "                x_test = x_test.reshape((num_images, rows, cols))\n",
        "        elif 't10k-labels' in f:\n",
        "            with gzip.open(f, 'rb') as data:\n",
        "                test_labels = data.read()[8:]\n",
        "                y_test = np.frombuffer(test_labels, dtype=np.uint8)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test    "
      ],
      "metadata": {
        "id": "9xTGitlWfjHq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui passamos o caminho: MNIST path\n",
        "# Obviamente os Dados já foram baixados com antecedencia\n",
        "\n",
        "mnist_path = '/content/drive/MyDrive/2_DEEP_LEARNING_REDES_NEURAIS_Jorge/1_Pytorch_Deep_Learning/Pytorch_examples/Rede_neural_exemplo_Pytorch/data/MNIST/raw/mnist_raw'"
      ],
      "metadata": {
        "id": "8JnCfstQf_m9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui utilizamos a função \"get_images()\" \n",
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
        "\n",
        "\n",
        "# Aquí dividimos nuestros Datos en train, val y test\n",
        "# También los convertimos a vectores\n",
        "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)\n",
        "y_train = y_train_num[:50000].reshape(50000, 1)\n",
        "\n",
        "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float)\n",
        "y_val = y_train_num[50000:].reshape(10000, 1)\n",
        "\n",
        "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float)\n",
        "y_test = y_test_num.copy().reshape(10000, 1)\n"
      ],
      "metadata": {
        "id": "lY4TLUphgLEU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizar imagens"
      ],
      "metadata": {
        "id": "vVbU9zEfmV8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizamos para ter uma média=0 e std=1\n",
        "\n",
        "def normalise(x_mean, x_std, x_data):\n",
        "  return (x_data - x_mean) / x_std\n"
      ],
      "metadata": {
        "id": "Q3cwjHOCilll"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "print(x_mean, x_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK4vzb63muDe",
        "outputId": "f9fe1479-f528-46ac-9bc4-f0f40a056c3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33.395157 78.66619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui teremos nossos Dados Normalizados\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ],
      "metadata": {
        "id": "zvaEhL1_o6yO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a média e std para Dados de Treinamento\n",
        "x_train.mean(), x_train.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj0gnQ_CpZkJ",
        "outputId": "d8f02932-be49-4964-a220-01064a59513c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.1638146e-07, 0.99999934)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a média e std para Dados de Validação\n",
        "x_val.mean(), x_val.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF0P7uGaq6AM",
        "outputId": "d0f24ad2-76ba-43f5-8b03-0051bbc15fb7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0058509559841872305, 0.9924333474151182)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizamos algumas das nossas Imagens"
      ],
      "metadata": {
        "id": "hX2PiVT5rRDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkCnjLTwrcct",
        "outputId": "2904a4ce-e1bd-4947-d407-8230b5da1614"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwb2Or4JrozS",
        "outputId": "1fdc8880-8850-4a3e-828e-7b986d81e467"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    "
      ],
      "metadata": {
        "id": "sGJuNNbJrPA2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'A imagem printada representa um: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "OnPfGCTPrab4",
        "outputId": "6cbb2e04-f1ef-46f6-f5bf-ce81dd180197"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A imagem printada representa um: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criamos a função de Mini-batches"
      ],
      "metadata": {
        "id": "Nfdv_697sKjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_minibatches(x, y, mb_size, shuffle = True):\n",
        "    '''\n",
        "    x  # Amostras, 784\n",
        "    y  # Amostras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Erro em quantidade de amostras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle: \n",
        "        idxs = np.arange(total_data)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ],
      "metadata": {
        "id": "0ZPjepGOraZC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agora sim ... PyTorch\n",
        "\n",
        "# Converter NumPy array a PyTorch"
      ],
      "metadata": {
        "id": "RX2tbIZHsmSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo para Tensores do PyTorch\n",
        "\n",
        "x_train_tensor = torch.tensor(x_train.copy())\n",
        "y_train_tensor = torch.tensor(y_train.copy())\n",
        "\n",
        "x_val_tensor = torch.tensor(x_val.copy())\n",
        "y_val_tensor = torch.tensor(y_val.copy())\n",
        "\n",
        "x_test_tensor = torch.tensor(x_test.copy())\n",
        "y_test_tensor = torch.tensor(y_test.copy())\n"
      ],
      "metadata": {
        "id": "-1dRlUkaraW2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usar GPU de estiver disponível"
      ],
      "metadata": {
        "id": "hTsx5PwMvch-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Estammos usando: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FIGoJ3draT9",
        "outputId": "5c5f1729-a77a-4365-b336-7cab317fdd0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estammos usando: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculamos Accuracy"
      ],
      "metadata": {
        "id": "l8DJSDKIxB93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, x, y, mb_size):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size ) - \"dim\" é do Pytorch\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1). squeeze() eliminará esse 1.\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "            return float(num_correct)/num_total"
      ],
      "metadata": {
        "id": "SK43KKoAxJy0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loop de Treinamento"
      ],
      "metadata": {
        "id": "fagzNo1tzmzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimiser, mb_size, epochs=100):\n",
        "    model = model.to(device=device)\n",
        "    for epoch in range(epochs):\n",
        "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # funcion cost\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimiser.zero_grad()\n",
        "            cost.backward()\n",
        "            optimiser.step()\n",
        "            \n",
        "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {accuracy(model, x_val_tensor, y_val_tensor, mb_size)}')"
      ],
      "metadata": {
        "id": "AyFJkxZZxJwT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usando Sequential"
      ],
      "metadata": {
        "id": "Nd2DukOW75BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciar modelo\n",
        "hidden1 = 1000 # Neurônios\n",
        "hidden = 1000\n",
        "lr = 5e-2\n",
        "epochs = 20 # 100\n",
        "mb_size = 2048 # 4096\n",
        "\n",
        "# Criamos nosso Modelo\n",
        "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden1), # Capa Linear\n",
        "                       nn.ReLU(), # Capa de função de Ativação\n",
        "                       nn.Linear(in_features=hidden1, out_features=hidden), # Outra capa Linear\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=hidden, out_features=10)) # A nossa saída é 10, porque temos 10 classes\n",
        "\n",
        "\n",
        "optimiser = torch.optim.SGD(model1.parameters(), lr=lr)\n",
        "\n",
        "train(model1, optimiser, mb_size, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ddrGqLpGh3",
        "outputId": "dbf5437e-a270-4890-a1cf-a3ae34d2a576"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, costo: 1.3201227188110352, accuracy: 0.77685546875\n",
            "Epoch: 1, costo: 0.6292073130607605, accuracy: 0.87939453125\n",
            "Epoch: 2, costo: 0.500742495059967, accuracy: 0.88134765625\n",
            "Epoch: 3, costo: 0.40553298592567444, accuracy: 0.88720703125\n",
            "Epoch: 4, costo: 0.40270867943763733, accuracy: 0.90576171875\n",
            "Epoch: 5, costo: 0.35970625281333923, accuracy: 0.9091796875\n",
            "Epoch: 6, costo: 0.31996676325798035, accuracy: 0.916015625\n",
            "Epoch: 7, costo: 0.3086887001991272, accuracy: 0.921875\n",
            "Epoch: 8, costo: 0.30536025762557983, accuracy: 0.91748046875\n",
            "Epoch: 9, costo: 0.292764276266098, accuracy: 0.92578125\n",
            "Epoch: 10, costo: 0.2877843677997589, accuracy: 0.9248046875\n",
            "Epoch: 11, costo: 0.2839469313621521, accuracy: 0.93359375\n",
            "Epoch: 12, costo: 0.28555312752723694, accuracy: 0.9296875\n",
            "Epoch: 13, costo: 0.2000976949930191, accuracy: 0.93359375\n",
            "Epoch: 14, costo: 0.2205757051706314, accuracy: 0.92529296875\n",
            "Epoch: 15, costo: 0.20942121744155884, accuracy: 0.92041015625\n",
            "Epoch: 16, costo: 0.2572483718395233, accuracy: 0.94677734375\n",
            "Epoch: 17, costo: 0.2393893599510193, accuracy: 0.9375\n",
            "Epoch: 18, costo: 0.2649387717247009, accuracy: 0.93994140625\n",
            "Epoch: 19, costo: 0.2339317351579666, accuracy: 0.9443359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(model1, x_test_tensor,  y_test_tensor, mb_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rll4uF3OpRML",
        "outputId": "90bdfad9-6d5d-4528-aae8-5ab8de5affad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.947265625"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}